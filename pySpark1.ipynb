{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPddUGbz0fERsKu4+jKYlG2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vivek-afk81/pyspark-learning-notes/blob/main/pySpark1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_B4VzYX1zmV",
        "outputId": "3256dd9b-3459-4241-b418-978d7eec9c12"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qsUE9Z-uvZF1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pyspark\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to a specific directory\n",
        "os.chdir('/content/drive/My Drive/pyspark')\n",
        "\n",
        "# Verify current directory\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtz1DwGj2LaT",
        "outputId": "57047232-692e-4786-e96a-fd4d6bd35734"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/pyspark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_excel(\"sample_pyspark_data.xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OVHl0Ovfy_Ik",
        "outputId": "792fd315-808b-4bd0-9551-90e6cd9a9d08"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id     name  age department  salary\n",
              "0   1    Alice   24         IT   50000\n",
              "1   2      Bob   28         HR   45000\n",
              "2   3  Charlie   32    Finance   60000\n",
              "3   4    David   26         IT   52000\n",
              "4   5      Eva   30  Marketing   48000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ecb017c-b8fb-4588-8581-6f19e3cca6a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>age</th>\n",
              "      <th>department</th>\n",
              "      <th>salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Alice</td>\n",
              "      <td>24</td>\n",
              "      <td>IT</td>\n",
              "      <td>50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Bob</td>\n",
              "      <td>28</td>\n",
              "      <td>HR</td>\n",
              "      <td>45000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Charlie</td>\n",
              "      <td>32</td>\n",
              "      <td>Finance</td>\n",
              "      <td>60000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>David</td>\n",
              "      <td>26</td>\n",
              "      <td>IT</td>\n",
              "      <td>52000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Eva</td>\n",
              "      <td>30</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>48000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ecb017c-b8fb-4588-8581-6f19e3cca6a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ecb017c-b8fb-4588-8581-6f19e3cca6a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ecb017c-b8fb-4588-8581-6f19e3cca6a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-04d63d33-e299-4d12-80d6-7797a053149f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04d63d33-e299-4d12-80d6-7797a053149f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-04d63d33-e299-4d12-80d6-7797a053149f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Bob\",\n          \"Eva\",\n          \"Charlie\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 24,\n        \"max\": 32,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          28,\n          30,\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"department\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"HR\",\n          \"Marketing\",\n          \"IT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5656,\n        \"min\": 45000,\n        \"max\": 60000,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          45000,\n          48000,\n          60000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(pd.read_csv(\"student_practice_data.csv\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "uUteYgOs6ly5",
        "outputId": "98e67039-a22a-48be-c921-6f63d3627d14"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index. This alignment also\n",
              "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
              "    Series/DataFrame inputs.\n",
              "\n",
              "    If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3\n",
              "\n",
              "Constructing DataFrame from Series/DataFrame:\n",
              "\n",
              "&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df\n",
              "   0\n",
              "a  1\n",
              "c  3\n",
              "\n",
              "&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df2\n",
              "   x\n",
              "a  1\n",
              "c  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 509);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Working with Spark\n",
        "\n",
        "1. Create a sprark session"
      ],
      "metadata": {
        "id": "Qm4P6ras3N_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "jeJqQuXH1iT6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('Practise').getOrCreate()"
      ],
      "metadata": {
        "id": "hfZZorre3dN_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "9czMxj9P3ocL",
        "outputId": "d9c390fe-0136-4765-f920-fdc6cf9083eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x79b6010bf770>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://9d99830726d6:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v4.0.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practise</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.csv(\"student_practice_data.csv\")\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Osi3kNoP3tTH",
        "outputId": "170222a5-b410-41cb-81ed-00f364497e25"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---+--------------+-----+---------+\n",
            "|       _c0|  _c1|_c2|           _c3|  _c4|      _c5|\n",
            "+----------+-----+---+--------------+-----+---------+\n",
            "|student_id| name|age|        course|score|     city|\n",
            "|       101|Aarav| 20|            AI|   85|    Delhi|\n",
            "|       102| Diya| 21|  Data Science|   90|   Mumbai|\n",
            "|       103|Karan| 19|Cyber Security|   78|     Pune|\n",
            "|       104|Meera| 22|            AI|   88|Bangalore|\n",
            "|       105|Rohit| 20|       Web Dev|   82|  Chennai|\n",
            "+----------+-----+---+--------------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading the data"
      ],
      "metadata": {
        "id": "zIrNClOpBMC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to remove these headers(_c0,_c1,....)\n",
        "df_pyspark=spark.read.option('header','true').csv('student_practice_data.csv')"
      ],
      "metadata": {
        "id": "qjVOU2D_4xqf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "zRgdekOz5-D0",
        "outputId": "abbaf95f-347e-4566-a785-06e2c291335c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.classic.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.classic.dataframe.DataFrame</b><br/>def __init__(jdf: &#x27;JavaObject&#x27;, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg(\n",
              "...         {&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).sort(&quot;max(age)&quot;).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|PySpark|     M|       75.0|      50|\n",
              "|     ML|     F|      150.0|      60|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 105);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNjh9G8i6xNJ",
        "outputId": "3a0d14ee-5bd7-4982-bbc4-eb0c12b2151d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(student_id='101', name='Aarav', age='20', course='AI', score='85', city='Delhi'),\n",
              " Row(student_id='102', name='Diya', age='21', course='Data Science', score='90', city='Mumbai'),\n",
              " Row(student_id='103', name='Karan', age='19', course='Cyber Security', score='78', city='Pune')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#basically this works as info\n",
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHR0Maru65zT",
        "outputId": "a20409d4-e15d-48e6-f609-76a20ae813dd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- student_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- course: string (nullable = true)\n",
            " |-- score: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_pyspark=spark.read.option('header','true').csv('student_practice_data.csv',inferSchema=True)\n",
        "#or we can use\n",
        "df_pyspark=spark.read.csv('student_practice_data.csv',header=True,inferSchema=True)\n",
        "df_pyspark.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyNyXrVc7MmP",
        "outputId": "e66c0d28-3966-49d5-a217-de4d9989c44e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---+--------------+-----+---------+\n",
            "|student_id| name|age|        course|score|     city|\n",
            "+----------+-----+---+--------------+-----+---------+\n",
            "|       101|Aarav| 20|            AI|   85|    Delhi|\n",
            "|       102| Diya| 21|  Data Science|   90|   Mumbai|\n",
            "|       103|Karan| 19|Cyber Security|   78|     Pune|\n",
            "|       104|Meera| 22|            AI|   88|Bangalore|\n",
            "|       105|Rohit| 20|       Web Dev|   82|  Chennai|\n",
            "+----------+-----+---+--------------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the Datatypes of the Column(Schema)"
      ],
      "metadata": {
        "id": "-4s1Bnh7CwHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL4J_bMiBuNT",
        "outputId": "c13a2ad5-5a32-49d8-8abb-bec45e2fc3f0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- student_id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- course: string (nullable = true)\n",
            " |-- score: integer (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Selecting Columns and Indexing"
      ],
      "metadata": {
        "id": "S4XE_70IC9q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvT5yF2lC7zn",
        "outputId": "2bb284fe-11b1-49e4-959b-56257fee9818"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['student_id', 'name', 'age', 'course', 'score', 'city']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVpEYsh8DGo6",
        "outputId": "dd8db87b-f1a7-4dd6-f79d-0bd7d26ce39a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---+--------------+-----+---------+\n",
            "|student_id| name|age|        course|score|     city|\n",
            "+----------+-----+---+--------------+-----+---------+\n",
            "|       101|Aarav| 20|            AI|   85|    Delhi|\n",
            "|       102| Diya| 21|  Data Science|   90|   Mumbai|\n",
            "|       103|Karan| 19|Cyber Security|   78|     Pune|\n",
            "|       104|Meera| 22|            AI|   88|Bangalore|\n",
            "|       105|Rohit| 20|       Web Dev|   82|  Chennai|\n",
            "+----------+-----+---+--------------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select('name').show()\n",
        "\n",
        "#selecting multiple columns\n",
        "df_pyspark.select('student_id','name','city').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w_OJWIiDSRR",
        "outputId": "cc52d4ea-fb8c-48df-8ede-441fe17ccf2f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| name|\n",
            "+-----+\n",
            "|Aarav|\n",
            "| Diya|\n",
            "|Karan|\n",
            "|Meera|\n",
            "|Rohit|\n",
            "+-----+\n",
            "\n",
            "+----------+-----+---------+\n",
            "|student_id| name|     city|\n",
            "+----------+-----+---------+\n",
            "|       101|Aarav|    Delhi|\n",
            "|       102| Diya|   Mumbai|\n",
            "|       103|Karan|     Pune|\n",
            "|       104|Meera|Bangalore|\n",
            "|       105|Rohit|  Chennai|\n",
            "+----------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Notice that the .select is returning a dataframe object\n",
        "type(df_pyspark.select('name'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "SSXOJ96EDbNV",
        "outputId": "73d165ab-b6a5-4a50-e1e4-6e663d5e22ef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.classic.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.classic.dataframe.DataFrame</b><br/>def __init__(jdf: &#x27;JavaObject&#x27;, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg(\n",
              "...         {&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).sort(&quot;max(age)&quot;).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|PySpark|     M|       75.0|      50|\n",
              "|     ML|     F|      150.0|      60|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 105);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the datatypes\n",
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX4vbZpoDty_",
        "outputId": "3a8a882c-ff15-47fb-b69c-3d569036808d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('student_id', 'int'),\n",
              " ('name', 'string'),\n",
              " ('age', 'int'),\n",
              " ('course', 'string'),\n",
              " ('score', 'int'),\n",
              " ('city', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edw15fxmEWxT",
        "outputId": "f33ac42d-1e48-4d19-9a56-b1b87611d8ab"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-----+-----------------+-------+----------------+---------+\n",
            "|summary|        student_id| name|              age| course|           score|     city|\n",
            "+-------+------------------+-----+-----------------+-------+----------------+---------+\n",
            "|  count|                 5|    5|                5|      5|               5|        5|\n",
            "|   mean|             103.0| NULL|             20.4|   NULL|            84.6|     NULL|\n",
            "| stddev|1.5811388300841898| NULL|1.140175425099138|   NULL|4.77493455452533|     NULL|\n",
            "|    min|               101|Aarav|               19|     AI|              78|Bangalore|\n",
            "|    max|               105|Rohit|               22|Web Dev|              90|     Pune|\n",
            "+-------+------------------+-----+-----------------+-------+----------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding And Dropping Columns"
      ],
      "metadata": {
        "id": "4n_ncJhRE5Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Returns a new DataFrame by adding a column or replacing the\n",
        "existing column that has the same name.\n",
        "\n",
        "The column expression must be an expression over this DataFrame; attempting to add\n",
        "a column from some other DataFrame will raise an error.'''\n",
        "from pyspark.sql.functions import rand, floor\n",
        "\n",
        "df_pyspark = df_pyspark.withColumn(\n",
        "    \"Score2\",\n",
        "    df_pyspark[\"score\"] + floor(rand() * 6)\n",
        ")\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Pyfmt0EEldu",
        "outputId": "525de9f6-c45f-49e9-982b-2ecd3b7c3aea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---+--------------+-----+---------+------+\n",
            "|student_id| name|age|        course|score|     city|Score2|\n",
            "+----------+-----+---+--------------+-----+---------+------+\n",
            "|       101|Aarav| 20|            AI|   85|    Delhi|    85|\n",
            "|       102| Diya| 21|  Data Science|   90|   Mumbai|    93|\n",
            "|       103|Karan| 19|Cyber Security|   78|     Pune|    78|\n",
            "|       104|Meera| 22|            AI|   88|Bangalore|    88|\n",
            "|       105|Rohit| 20|       Web Dev|   82|  Chennai|    82|\n",
            "+----------+-----+---+--------------+-----+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping a columns\n",
        "df_pyspark=df_pyspark.drop('Score2')\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEWqczp4GJxN",
        "outputId": "3ed7597b-7997-4555-f99d-b66f2e1dd3cd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---+--------------+-----+---------+\n",
            "|student_id| name|age|        course|score|     city|\n",
            "+----------+-----+---+--------------+-----+---------+\n",
            "|       101|Aarav| 20|            AI|   85|    Delhi|\n",
            "|       102| Diya| 21|  Data Science|   90|   Mumbai|\n",
            "|       103|Karan| 19|Cyber Security|   78|     Pune|\n",
            "|       104|Meera| 22|            AI|   88|Bangalore|\n",
            "|       105|Rohit| 20|       Web Dev|   82|  Chennai|\n",
            "+----------+-----+---+--------------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename a columns\n",
        "\n",
        "df_pyspark.withColumnRenamed('name','Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCW-8bPvHKcm",
        "outputId": "b69e8c4b-d967-4ca7-a34b-8ebd588d5be1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+---+--------------+-----+---------+\n",
            "|student_id| Name|age|        course|score|     city|\n",
            "+----------+-----+---+--------------+-----+---------+\n",
            "|       101|Aarav| 20|            AI|   85|    Delhi|\n",
            "|       102| Diya| 21|  Data Science|   90|   Mumbai|\n",
            "|       103|Karan| 19|Cyber Security|   78|     Pune|\n",
            "|       104|Meera| 22|            AI|   88|Bangalore|\n",
            "|       105|Rohit| 20|       Web Dev|   82|  Chennai|\n",
            "+----------+-----+---+--------------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Handling missing values\n",
        "\n",
        "1. Dropping Columns\n",
        "2. Dropping Rows\n",
        "3. Various Parameter in Dropping Functionalities\n",
        "\n",
        "4. Handeling Missing values by Mean,Median and Mode"
      ],
      "metadata": {
        "id": "tc1DS6K8KqBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DF=spark.read.csv(\"missing_values_practice.csv\",header=True,inferSchema=True)\n",
        "DF.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en0fSOCfHtPc",
        "outputId": "8e477a6c-d4b2-4762-9954-3e23aa8b53f6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+----+----------+----------------+------+\n",
            "|employee_id| name| age|department|experience_years|rating|\n",
            "+-----------+-----+----+----------+----------------+------+\n",
            "|        201| Amit|25.0|        IT|             2.0|   4.5|\n",
            "|        202| Neha|NULL|        HR|             3.0|  NULL|\n",
            "|        203| Ravi|30.0|      NULL|            NULL|   3.8|\n",
            "|        204|Priya|28.0|   Finance|             5.0|  NULL|\n",
            "|        205| NULL|35.0|        IT|             7.0|   4.2|\n",
            "|        206|Suman|NULL|        HR|            NULL|   3.9|\n",
            "+-----------+-----+----+----------+----------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's add a column Salary also\n",
        "from pyspark.sql.functions import when, col,rand\n",
        "\n",
        "\n",
        "DF = DF.withColumn(\n",
        "    \"Salary\",\n",
        "    floor(rand() * 50000 + 30000)\n",
        ")\n",
        "\n",
        "#now introducing null values\n",
        "DF = DF.withColumn(\n",
        "    \"Salary\",\n",
        "    when(rand() < 0.2, None)\n",
        "    .otherwise(col(\"Salary\"))\n",
        ")\n",
        "\n",
        "DF.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRagdvupNjbF",
        "outputId": "8f6c23d6-66e0-4845-9831-7d0e7e8aa02d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "|employee_id| name| age|department|experience_years|rating|Salary|\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "|        201| Amit|25.0|        IT|             2.0|   4.5| 63221|\n",
            "|        202| Neha|NULL|        HR|             3.0|  NULL| 50978|\n",
            "|        203| Ravi|30.0|      NULL|            NULL|   3.8|  NULL|\n",
            "|        204|Priya|28.0|   Finance|             5.0|  NULL| 79370|\n",
            "|        205| NULL|35.0|        IT|             7.0|   4.2| 34429|\n",
            "|        206|Suman|NULL|        HR|            NULL|   3.9|  NULL|\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This will remove all those rows which ahve null values present in it\n",
        "DF.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOxhaGWcONBG",
        "outputId": "4d101fdf-f909-4e46-f055-d322ec5692bd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----+----+----------+----------------+------+------+\n",
            "|employee_id|name| age|department|experience_years|rating|Salary|\n",
            "+-----------+----+----+----------+----------------+------+------+\n",
            "|        201|Amit|25.0|        IT|             2.0|   4.5| 63221|\n",
            "+-----------+----+----+----------+----------------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# any=how\n",
        "DF.na.drop(how='all').show() # it will drop those rows which have all null values in this case there are'nt any\n",
        "DF.na.drop(how='any').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRHUt6vCQiCP",
        "outputId": "85514e3e-9f71-4282-a38b-862d83a20579"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "|employee_id| name| age|department|experience_years|rating|Salary|\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "|        201| Amit|25.0|        IT|             2.0|   4.5| 63221|\n",
            "|        202| Neha|NULL|        HR|             3.0|  NULL| 50978|\n",
            "|        203| Ravi|30.0|      NULL|            NULL|   3.8|  NULL|\n",
            "|        204|Priya|28.0|   Finance|             5.0|  NULL| 79370|\n",
            "|        205| NULL|35.0|        IT|             7.0|   4.2| 34429|\n",
            "|        206|Suman|NULL|        HR|            NULL|   3.9|  NULL|\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "\n",
            "+-----------+----+----+----------+----------------+------+------+\n",
            "|employee_id|name| age|department|experience_years|rating|Salary|\n",
            "+-----------+----+----+----------+----------------+------+------+\n",
            "|        201|Amit|25.0|        IT|             2.0|   4.5| 63221|\n",
            "+-----------+----+----+----------+----------------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Threshold\n",
        "DF.na.drop(how=\"any\",thresh=5).show() #it says atleast 5 non null values must be there, in this case only 2nd row has 4 non null values hence it got dropped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49zo8JnGRGPT",
        "outputId": "eca23985-dcdd-476d-dd9d-62886e40598c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "|employee_id| name| age|department|experience_years|rating|Salary|\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "|        201| Amit|25.0|        IT|             2.0|   4.5| 63221|\n",
            "|        202| Neha|NULL|        HR|             3.0|  NULL| 50978|\n",
            "|        204|Priya|28.0|   Finance|             5.0|  NULL| 79370|\n",
            "|        205| NULL|35.0|        IT|             7.0|   4.2| 34429|\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Subset when you want to drop nan values with respect to a specific columns\n",
        "DF.na.drop(how='any',subset=['experience_years']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYuKcMnhSH-i",
        "outputId": "fd5937cf-f9a2-4989-9edd-5891ba0eca83"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "|employee_id| name| age|department|experience_years|rating|Salary|\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "|        201| Amit|25.0|        IT|             2.0|   4.5| 63221|\n",
            "|        202| Neha|NULL|        HR|             3.0|  NULL| 50978|\n",
            "|        204|Priya|28.0|   Finance|             5.0|  NULL| 79370|\n",
            "|        205| NULL|35.0|        IT|             7.0|   4.2| 34429|\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the Missing Values\n",
        "DF.na.fill('Missing_values').show() #Spark interprets this as:Fill STRING columns only with 'Missing_values'\n",
        "DF.na.fill('Missing_values',['experience_years','age']).show()#Spark will NOT insert a string into numeric columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upeW9iexUXyz",
        "outputId": "06e2bfc0-32fd-4bd8-8fd5-450e041e6b33"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+----+--------------+----------------+------+------+\n",
            "|employee_id|          name| age|    department|experience_years|rating|Salary|\n",
            "+-----------+--------------+----+--------------+----------------+------+------+\n",
            "|        201|          Amit|25.0|            IT|             2.0|   4.5| 63221|\n",
            "|        202|          Neha|NULL|            HR|             3.0|  NULL| 50978|\n",
            "|        203|          Ravi|30.0|Missing_values|            NULL|   3.8|  NULL|\n",
            "|        204|         Priya|28.0|       Finance|             5.0|  NULL| 79370|\n",
            "|        205|Missing_values|35.0|            IT|             7.0|   4.2| 34429|\n",
            "|        206|         Suman|NULL|            HR|            NULL|   3.9|  NULL|\n",
            "+-----------+--------------+----+--------------+----------------+------+------+\n",
            "\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "|employee_id| name| age|department|experience_years|rating|Salary|\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "|        201| Amit|25.0|        IT|             2.0|   4.5| 63221|\n",
            "|        202| Neha|NULL|        HR|             3.0|  NULL| 50978|\n",
            "|        203| Ravi|30.0|      NULL|            NULL|   3.8|  NULL|\n",
            "|        204|Priya|28.0|   Finance|             5.0|  NULL| 79370|\n",
            "|        205| NULL|35.0|        IT|             7.0|   4.2| 34429|\n",
            "|        206|Suman|NULL|        HR|            NULL|   3.9|  NULL|\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DF.show()"
      ],
      "metadata": {
        "id": "Whc8I5S8U5GH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b1499b-43dd-4a46-95a3-a7a60983410e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "|employee_id| name| age|department|experience_years|rating|Salary|\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "|        201| Amit|25.0|        IT|             2.0|   4.5| 63221|\n",
            "|        202| Neha|NULL|        HR|             3.0|  NULL| 50978|\n",
            "|        203| Ravi|30.0|      NULL|            NULL|   3.8|  NULL|\n",
            "|        204|Priya|28.0|   Finance|             5.0|  NULL| 79370|\n",
            "|        205| NULL|35.0|        IT|             7.0|   4.2| 34429|\n",
            "|        206|Suman|NULL|        HR|            NULL|   3.9|  NULL|\n",
            "+-----------+-----+----+----------+----------------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer=Imputer(\n",
        "    inputCols=['age','experience_years','Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['age','experience_years','Salary']]\n",
        ").setStrategy(\"mean\")\n",
        "\n",
        "# changing he strategu to median\n",
        "imputer_2=Imputer(\n",
        "    inputCols=['age','experience_years','Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['age','experience_years','Salary']]\n",
        ").setStrategy(\"median\")"
      ],
      "metadata": {
        "id": "Ji6XhtglGBN1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding imputation cols to th DF\n",
        "\n",
        "imputer.fit(DF).transform(DF).show()\n",
        "imputer_2.fit(DF).transform(DF).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjEgZIORHPXa",
        "outputId": "d9c3950c-0c0e-4dd6-e19a-400bb9d92ef1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+----+----------+----------------+------+------+-----------+------------------------+--------------+\n",
            "|employee_id| name| age|department|experience_years|rating|Salary|age_imputed|experience_years_imputed|Salary_imputed|\n",
            "+-----------+-----+----+----------+----------------+------+------+-----------+------------------------+--------------+\n",
            "|        201| Amit|25.0|        IT|             2.0|   4.5| 63221|       25.0|                     2.0|         63221|\n",
            "|        202| Neha|NULL|        HR|             3.0|  NULL| 50978|       29.5|                     3.0|         50978|\n",
            "|        203| Ravi|30.0|      NULL|            NULL|   3.8|  NULL|       30.0|                    4.25|         56999|\n",
            "|        204|Priya|28.0|   Finance|             5.0|  NULL| 79370|       28.0|                     5.0|         79370|\n",
            "|        205| NULL|35.0|        IT|             7.0|   4.2| 34429|       35.0|                     7.0|         34429|\n",
            "|        206|Suman|NULL|        HR|            NULL|   3.9|  NULL|       29.5|                    4.25|         56999|\n",
            "+-----------+-----+----+----------+----------------+------+------+-----------+------------------------+--------------+\n",
            "\n",
            "+-----------+-----+----+----------+----------------+------+------+-----------+------------------------+--------------+\n",
            "|employee_id| name| age|department|experience_years|rating|Salary|age_imputed|experience_years_imputed|Salary_imputed|\n",
            "+-----------+-----+----+----------+----------------+------+------+-----------+------------------------+--------------+\n",
            "|        201| Amit|25.0|        IT|             2.0|   4.5| 63221|       25.0|                     2.0|         63221|\n",
            "|        202| Neha|NULL|        HR|             3.0|  NULL| 50978|       28.0|                     3.0|         50978|\n",
            "|        203| Ravi|30.0|      NULL|            NULL|   3.8|  NULL|       30.0|                     3.0|         50978|\n",
            "|        204|Priya|28.0|   Finance|             5.0|  NULL| 79370|       28.0|                     5.0|         79370|\n",
            "|        205| NULL|35.0|        IT|             7.0|   4.2| 34429|       35.0|                     7.0|         34429|\n",
            "|        206|Suman|NULL|        HR|            NULL|   3.9|  NULL|       28.0|                     3.0|         50978|\n",
            "+-----------+-----+----+----------+----------------+------+------+-----------+------------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pyspark DataFrames"
      ],
      "metadata": {
        "id": "7_gLG6dGISo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets use the excel file from the beginning\n",
        "#PySpark CANNOT natively read Excel (.xlsx)\n",
        "#Spark works best with CSV / Parquet / JSON / ORC\n",
        "\n",
        "df_pd = pd.read_excel(\"sample_pyspark_data.xlsx\")"
      ],
      "metadata": {
        "id": "IoWGx6_MHac9"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pd.to_csv(\"test1.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "FMGO_ET8JsYs"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark = spark.read.csv(\n",
        "    \"test1.csv\",\n",
        "    header=True,\n",
        "    inferSchema=True\n",
        ")\n",
        "\n",
        "df_spark.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "couruHlCJv_O",
        "outputId": "b65d8db2-208a-49e5-c75b-155cd65a8d94"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+---+----------+------+\n",
            "| id|   name|age|department|salary|\n",
            "+---+-------+---+----------+------+\n",
            "|  1|  Alice| 24|        IT| 50000|\n",
            "|  2|    Bob| 28|        HR| 45000|\n",
            "|  3|Charlie| 32|   Finance| 60000|\n",
            "|  4|  David| 26|        IT| 52000|\n",
            "|  5|    Eva| 30| Marketing| 48000|\n",
            "+---+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Filter operations"
      ],
      "metadata": {
        "id": "hmoXC37PKJYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salary of people less than 50,000\n",
        "df_spark.filter(\"salary<=50000\").show()\n",
        "#or\n",
        "df_spark.filter(df_spark['salary']<49000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg5QwSuUKCw5",
        "outputId": "20fa3c19-eba2-4281-cf72-89da476b9135"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+---+----------+------+\n",
            "| id| name|age|department|salary|\n",
            "+---+-----+---+----------+------+\n",
            "|  1|Alice| 24|        IT| 50000|\n",
            "|  2|  Bob| 28|        HR| 45000|\n",
            "|  5|  Eva| 30| Marketing| 48000|\n",
            "+---+-----+---+----------+------+\n",
            "\n",
            "+---+----+---+----------+------+\n",
            "| id|name|age|department|salary|\n",
            "+---+----+---+----------+------+\n",
            "|  2| Bob| 28|        HR| 45000|\n",
            "|  5| Eva| 30| Marketing| 48000|\n",
            "+---+----+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.filter(\"salary<=50000\").select(['name','age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSxtPNnzKb_5",
        "outputId": "7bebfb0c-20e6-4192-f008-5ec6d4f85839"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "|Alice| 24|\n",
            "|  Bob| 28|\n",
            "|  Eva| 30|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding multiple condittions\n",
        "\n",
        "df_spark.filter((df_spark['salary']<49000) | (df_spark['age']>35)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ekbLAekKw82",
        "outputId": "e6939f48-6787-4d68-cd49-baef9bc6f6a5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+---+----------+------+\n",
            "| id|name|age|department|salary|\n",
            "+---+----+---+----------+------+\n",
            "|  2| Bob| 28|        HR| 45000|\n",
            "|  5| Eva| 30| Marketing| 48000|\n",
            "+---+----+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the not condition\n",
        "df_spark.filter(~(df_spark['salary']<49000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on_uF9PHL-Px",
        "outputId": "bc76cd59-dde5-422a-8d3a-c5cf765d40a3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+---+----------+------+\n",
            "| id|   name|age|department|salary|\n",
            "+---+-------+---+----------+------+\n",
            "|  1|  Alice| 24|        IT| 50000|\n",
            "|  3|Charlie| 32|   Finance| 60000|\n",
            "|  4|  David| 26|        IT| 52000|\n",
            "+---+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pyspark GroupBy And Aggregate Functions"
      ],
      "metadata": {
        "id": "XMZHqqIDNc3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4xCD3_6OHT3",
        "outputId": "194a2a59-2ed1-4578-a552-4472a2056fb4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##GroupBy\n",
        "# Group by and aggregate functions go hand in hand\n",
        "df_spark.groupBy('name').sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_0_lPgtOQ9E",
        "outputId": "e52c91a6-f0e8-4ff3-8f82-8cd1e28fee87"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[name: string, sum(id): bigint, sum(age): bigint, sum(salary): bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.groupBy('name').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfpz_nDvOp3n",
        "outputId": "b0758dcb-3dfa-45d6-ec49-dfa36522f415"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+--------+-----------+\n",
            "|   name|sum(id)|sum(age)|sum(salary)|\n",
            "+-------+-------+--------+-----------+\n",
            "|    Eva|      5|      30|      48000|\n",
            "|Charlie|      3|      32|      60000|\n",
            "|    Bob|      2|      28|      45000|\n",
            "|  Alice|      1|      24|      50000|\n",
            "|  David|      4|      26|      52000|\n",
            "+-------+-------+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# group by departments to see which department gives max salary\n",
        "df_spark.groupBy('department').sum('salary').show()\n",
        "df_spark.groupBy('department').mean('salary').show()\n",
        "df_spark.groupBy('department').count().show() # to check no of employees working in each department"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu87QvpgO1Rn",
        "outputId": "b99aee69-ba81-4747-d4eb-53494487d51f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|department|sum(salary)|\n",
            "+----------+-----------+\n",
            "|        HR|      45000|\n",
            "|   Finance|      60000|\n",
            "| Marketing|      48000|\n",
            "|        IT|     102000|\n",
            "+----------+-----------+\n",
            "\n",
            "+----------+-----------+\n",
            "|department|avg(salary)|\n",
            "+----------+-----------+\n",
            "|        HR|    45000.0|\n",
            "|   Finance|    60000.0|\n",
            "| Marketing|    48000.0|\n",
            "|        IT|    51000.0|\n",
            "+----------+-----------+\n",
            "\n",
            "+----------+-----+\n",
            "|department|count|\n",
            "+----------+-----+\n",
            "|        HR|    1|\n",
            "|   Finance|    1|\n",
            "| Marketing|    1|\n",
            "|        IT|    2|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "df_spark.groupBy(\"name\") \\\n",
        "    .max(\"salary\") \\\n",
        "    .orderBy(desc(\"max(salary)\")) \\\n",
        "    .show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weOA7OO2RYxz",
        "outputId": "75d554db-f155-474c-e4f3-701b765f80da"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|   name|max(salary)|\n",
            "+-------+-----------+\n",
            "|Charlie|      60000|\n",
            "|  David|      52000|\n",
            "|  Alice|      50000|\n",
            "|    Eva|      48000|\n",
            "|    Bob|      45000|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QavGTfbcSrmg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}